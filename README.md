# Cloudera Nifi Hands On Lab

![alt text](/img/main1.png)

## About this Hands On Lab

This hands-on lab provides ...

## Agenda

### Section 1: Overview of Cloudera Dataflow
* Before Starting the Labs
* Lab 1. Overview of the Cloudera Data Flow Service
      
### Section 2: Quality of Service Ingest Use Case
**Pre-Requisites**
* Lab 1: Pre-Requisites
  
**NiFi Development**
* Lab 2: Deploy a NiFi Flow from the Catalog
* Lab 3: Navigating to your Deployment and Opening the Canvas
* Lab 4: Building on the Canvas
* Lab 5: Running the NiFi Canvas and Viewing the Output
  
**Analysing Kafka via Streams Messaging Manager**
* Lab 6: Access Streams Messaging Manager
* Lab 7: Explore Topics
* Lab 8: Review Topic Details
  
**Interacting with Kafka via Flink SQL**
* Lab 9: To access the Flink Streaming SQL Console
* Lab 10: Keytab Unlock
* Lab 11: Project Navigation
* Lab 12: Running Flink SQL Jobs
  
**Appendix**

### Section 3: Quality of Service via Stateless Model Use Case

* Lab 1: Deploy a NiFi Flow from the Catalog
* Lab 2: Building on the Canvas
* Lab 3: Running the NiFi Canvas and Viewing the Output

### Section 4: Custom Python Processors Ingest Use Case

* Lab 1: Deploy a NiFi Flow from the Catalog
* Lab 2: Navigating to your Deployment and Opening the Canvas
  

## Step by Step Instructions

Detailed instructions are provided in the step_by_step_guides below. The hand-on labs are divided into trwo sections:

* [Section 1: Overview of Cloudera Dataflow](step-by-step-guides/Section%201%3A%20Overview%20of%20Cloudera%20DataFlow.md)
* [Section 2: Quality of Service Ingest Use Case](step-by-step-guides/Section%202%3A%20Quality%20of%20Service%20Ingest%20Use%20Case.md)
* [Section 3: Quality of Service via Stateless Model Use Case](step-by-step-guides/Section%203%3A%20Quality%20of%20Service%20via%20Stateless%20Model%20Use%20Case.md)
* [Section 4: Custom Python Processors Ingest Use Case](step-by-step-guides/Section%204%3A%20Custom%20Python%20Processors%20Ingest%20Use%20Case.md)

## Setup Instructions

The HOL requires data and dependencies to be created before the event. The attached [Setup Guide](https://github.com/richard-vh/iceberg-spark-hol/blob/main/setup/README.md) provides instructions for completing these requirements.

